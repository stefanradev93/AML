{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gloria/programs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import (Input, Dense, Embedding, Lambda,\n",
    "                                     Bidirectional, RepeatVector, Concatenate, Dot, Softmax, GaussianDropout)\n",
    "from tensorflow.keras.layers import CuDNNLSTM as LSTM\n",
    "from tensorflow.keras.layers import CuDNNGRU as GRU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this if you want to train with attentiopn to True, otherwise False\n",
    "ATTENTION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cornell(foldername, encoding='ISO-8859-1'):\n",
    "    \"\"\"\n",
    "    Loads the cornell movie dialogs.\n",
    "    ----------\n",
    "    INPUT:\n",
    "    foldername : string - the path to the movie dialogs (relative or absolute)\n",
    "    ----------\n",
    "    OUTPUT:\n",
    "    questions  : list - a list containing preceeding phrases\n",
    "    answers    : list - a list containing following phrases \n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in dialogs\n",
    "    with open(os.path.join(foldername, 'movie_lines.txt'), 'r', encoding=encoding, errors='ignore') as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    with open(os.path.join(foldername, 'movie_conversations.txt'), 'r', encoding=encoding, errors='ignore') as f:\n",
    "        ids = f.read().splitlines()\n",
    "        \n",
    "    # Create an id to line dictionary\n",
    "    split_token = ' +++$+++ '\n",
    "    id2line = {l.split(split_token)[0] : l.split(split_token)[4] for l in lines}\n",
    "    \n",
    "    # Create a list of conversations\n",
    "    conversations_ids = []\n",
    "    for conv in ids[:-1]:\n",
    "        _conv = conv.split(split_token)[-1][1:-1].replace(\"'\", '').replace(\" \", \"\")\n",
    "        conversations_ids.append(_conv.split(','))\n",
    "    \n",
    "    # Extract 'questions' and 'answers'\n",
    "    questions = [id2line[ids[i]] for ids in conversations_ids for i in range(len(ids) - 1)]\n",
    "    answers = [id2line[ids[i+1]] for ids in conversations_ids for i in range(len(ids) - 1)]\n",
    "    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    A custom sequence generator aimed at circumventing the MemoryError\n",
    "    problem caused by creating large non-sparse numpy matrices. It uses keras backend.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 encoder_input, \n",
    "                 decoder_input, \n",
    "                 decoder_targets, \n",
    "                 batch_size=64, \n",
    "                 n_classes=None, \n",
    "                 shuffle=True,\n",
    "                 attention=False,\n",
    "                 latent_dim=None):\n",
    "        \n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.decoder_targets = decoder_targets\n",
    "        self.n_classes = n_classes\n",
    "        if self.n_classes is None:\n",
    "            self.n_classes = np.max(self.decoder_targets) + 1\n",
    "        self.shuffle = shuffle\n",
    "        self.attention = attention\n",
    "        self.latent_dim = latent_dim\n",
    "        if self.attention and self.latent_dim is None:\n",
    "            raise ValueError('If you are using attention, generator also needs latent dim of decoder RNN!')\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(self.encoder_input.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one batch at call.\"\"\"\n",
    "        \n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Sfuffle indexes after each epoch.\"\"\"\n",
    "        \n",
    "        self.indexes = np.arange(self.encoder_input.shape[0])\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        \"\"\"Generates data containing the batch samples.\"\"\"\n",
    "        \n",
    "        # Simply select and one-hot encode the data\n",
    "        encoder_input_batch = self.encoder_input[indexes, :]\n",
    "        decoder_input_batch = self.decoder_input[indexes, :]\n",
    "        decoder_targets_batch = self.decoder_targets[indexes, :]\n",
    "        # If we are using attention, we also need to batch out the initial decoder states\n",
    "        if self.attention:\n",
    "            s = np.zeros((self.batch_size, self.latent_dim))\n",
    "            inputs = [encoder_input_batch, decoder_input_batch, s, s]\n",
    "        else:\n",
    "            inputs = [encoder_input_batch, decoder_input_batch]\n",
    "        outputs = to_categorical(decoder_targets_batch, num_classes=self.n_classes) \n",
    "        return (inputs, outputs)\n",
    "    \n",
    "    def test_generator(self, preprocessor, n_steps=3):\n",
    "        \"\"\"A function to test if generator is meaningful.\"\"\"\n",
    "        \n",
    "        for i, batch in enumerate(self):\n",
    "            \n",
    "            (inps_batch, targets_batch) = batch\n",
    "        \n",
    "            print('*' * 10)\n",
    "            print('Batch ', i+1)\n",
    "            # If attention, we need to unpack 4 values, since the cell and hidden states are also inputs\n",
    "            if self.attention:\n",
    "                encoder_input_batch, decoder_input_batch, _, _ = inps_batch\n",
    "            else:\n",
    "                encoder_input_batch, decoder_input_batch = inps_batch\n",
    "            print('Shape of encoder_input_batch: ', encoder_input_batch.shape)\n",
    "            print('Shape of decoder_input_batch: ', decoder_input_batch.shape)\n",
    "            print('Shape of targets_batch: ', targets_batch.shape)\n",
    "\n",
    "            # Check dialogs\n",
    "            print('Dialogs: ')\n",
    "            for d in range(encoder_input_batch.shape[0]):\n",
    "                print(preprocessor.decode_input_sequence(encoder_input_batch[d]))\n",
    "                print(preprocessor.decode_output_sequence(decoder_input_batch[d]))\n",
    "                print('-' * 20)  \n",
    "\n",
    "            # Break after n steps\n",
    "            if (i+1) % n_steps == 0:\n",
    "                break\n",
    "                self.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(glove_dir, word_index, max_words, embedding_dim=100):\n",
    "    \"\"\"\n",
    "    A function to load pre-trained embeddings and return them as a N x M numpy array.\n",
    "    --------\n",
    "    INPUT:\n",
    "    glove_dir : string  - the path (relative or absolute to the glove vector text files)\n",
    "    \n",
    "    word_index : dict   - a word - index mapping obtained by a keras Tokenizer or manually\n",
    "    \n",
    "    max_words : int     - the maximum number of words in the vocabulary used for the application\n",
    "    \n",
    "    embedding_dim : int - the dimensionality of the embedding space\n",
    "    ---------\n",
    "    OUTPUT:\n",
    "    embedding_matrix : (max_words, embedding_dim) ndarray - the matrix of embeddings which can be\n",
    "                                                            directly loaded into an Embedding layer\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Create a word - vec dictionary from the pre-trained glvoe vectors\n",
    "    embeddings_index = {}\n",
    "    with open(os.path.join(glove_dir, 'glove.6B.100d.txt'), 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.array(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "            \n",
    "    # Now we will build an embedding matrix that we can load into an Embedding layer.\n",
    "    # It iwll be of shape (max_words, embedding_dim), where each entry i will contain\n",
    "    # the embedding for the word of index i in the reference built during tokenization.\n",
    "    # Index 0 is a placeholder!\n",
    "    \n",
    "    embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i < max_words:\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqPreprocessor:\n",
    "    \"\"\"\n",
    "    A class to bundle utility functions useful for preprocessing nlp data for a seq2seq model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_seq_len=50, vocab_size=20000):\n",
    "        \"\"\"\n",
    "        Initializes preprocessor instance.\n",
    "        ----------\n",
    "        INPUT:\n",
    "        max_seq_len : int - defines the longest sentence allowed. If a Q or an A in a Q&A pair\n",
    "                            contains more than max_seq_len, it will be later discarded.\n",
    "                            \n",
    "        vocab_size  : int - the maximum number of words in the vocabulary. Used by keras' Tokenizer\n",
    "        \"\"\"\n",
    "        \n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.input_tokenizer = Tokenizer(num_words=vocab_size, filters='')\n",
    "        self.output_tokenizer = Tokenizer(num_words=vocab_size, filters='')\n",
    "        self.idx2word_input = {}\n",
    "        self.idx2word_output = {}\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"\n",
    "        A custom preprocessing of the input texts. It lowers the text, replaces all short \n",
    "        verb forms with their full counterparts (I'm => I am), and removes all non-alphanumeric \n",
    "        characters as well as multiple spaces with single spaces.\n",
    "        ----------\n",
    "        INPUT:\n",
    "        text : string - a line of text to be cleaned\n",
    "        ----------\n",
    "        OUTPUT\n",
    "        text : string - the cleaned line of text\n",
    "        \"\"\"\n",
    "        \n",
    "        # Put all lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Pronouns\n",
    "        text = re.sub(r\"i'm\", \"i am\", text)\n",
    "        text = re.sub(r\"he's\", \"he is\", text)\n",
    "        text = re.sub(r\"she's\", \"she is\", text)\n",
    "        text = re.sub(r\"it's\", \"it is\", text)\n",
    "        \n",
    "        # Questions\n",
    "        text = re.sub(r\"that's\", \"that is\", text)\n",
    "        text = re.sub(r\"why's\", \"why is\", text)\n",
    "        text = re.sub(r\"what's\", \"what is\", text)\n",
    "        text = re.sub(r\"where's\", \"where is\", text)\n",
    "        text = re.sub(r\"here's\", \"here is\", text)\n",
    "        \n",
    "        # Negations\n",
    "        text = re.sub(r\"hasn't\", \"has not\", text)\n",
    "        text = re.sub(r\"won't\", \"will not\", text)\n",
    "        text = re.sub(r\"wouldn't\", \"would not\", text)\n",
    "        text = re.sub(r\"shouldn't\", \"should not\", text)\n",
    "        text = re.sub(r\"mustn't\", \"must not\", text)\n",
    "        text = re.sub(r\"haven't\", \"have not\", text)\n",
    "        text = re.sub(r\"hadn't\", \"had not\", text)\n",
    "        text = re.sub(r\"can't\", \"cannot\", text)\n",
    "        text = re.sub(r\"didn't\", \"did not\", text)\n",
    "        text = re.sub(r\"doesn't\", \"does not\", text)\n",
    "        text = re.sub(r\"don't\", \"do not\", text)\n",
    "        text = re.sub(r\"aren't\", \"are not\", text)\n",
    "        \n",
    "        # Modals\n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        \n",
    "        # Keep only alphanumeric and space\n",
    "        text = re.sub(r\"([^\\s\\w]|_)+\", \"\", text)\n",
    "        # Keep only single spaces\n",
    "        text = re.sub('\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def _add_sos(self, text):\n",
    "        return '<sos> ' + text \n",
    "\n",
    "    def _add_eos(self, text):\n",
    "        return text + ' <eos>'  \n",
    "    \n",
    "    def clean_texts(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Applies clean_text() to each input/targets pair. Adds EOS token to inputs and SOS to targets.\n",
    "        ----------\n",
    "        INPUT:\n",
    "        inputs  - list        : a list of input sentences (strings)\n",
    "        targets - list        : a list of target sentences (strings)\n",
    "        ----------\n",
    "        OUTPUT:\n",
    "        inputs_cleaned        : list - a list of the cleaned input sentences\n",
    "        targets_cleaned       : list - a list of the cleaned target sentences used as decoder output\n",
    "        targets_input_cleaned : list - a list of the cleaned sentences used as decoder input (teacher forcing)\n",
    "        \"\"\"\n",
    "        \n",
    "        assert len(inputs) == len(targets), 'Input and target length must match!'\n",
    "        \n",
    "        # Clean inputs and targets\n",
    "        inputs_cleaned = [self.clean_text(inp) for inp in inputs]\n",
    "        targets_cleaned = [self.clean_text(t) for t in targets]\n",
    "    \n",
    "        # Remove sequences larger than max sequence length\n",
    "        # First figure out indices of sentences to be removed\n",
    "        idx_to_remove = []\n",
    "        for i in range(len(inputs_cleaned)):\n",
    "            inp_len = len(inputs_cleaned[i].split())\n",
    "            target_len = len(targets_cleaned[i].split()) - 1 # we will later add eos and sos\n",
    "            if inp_len > self.max_seq_len or target_len > self.max_seq_len - 1:\n",
    "                idx_to_remove.append(i)\n",
    "        \n",
    "        # Then remove (not in-place)\n",
    "        inputs_cleaned = np.delete(inputs_cleaned, idx_to_remove)\n",
    "        targets_cleaned = np.delete(targets_cleaned, idx_to_remove)\n",
    "        \n",
    "        # Add EOS and SOS tokens, creating the input_targets list (no need for sos in decoder inputs)\n",
    "        targets_cleaned = [self._add_eos(t) for t in targets_cleaned]\n",
    "        targets_input_cleaned = [self._add_sos(t.replace('<eos>', '')) for t in targets_cleaned]\n",
    "        \n",
    "        return inputs_cleaned, targets_cleaned, targets_input_cleaned\n",
    "    \n",
    "    def tokenize_texts(self, inputs, targets, input_targets):\n",
    "        \"\"\"\n",
    "        Tokenizes the three lists of cleaned texsts using keras' Tokenizer, and padds with zeros\n",
    "        ----------\n",
    "        INPUT:\n",
    "        inputs           : list - a list of cleaned input texts (for encoder inpout)\n",
    "        targets          : list - a list of cleaned target texts with EOS (decoder output)\n",
    "        input_targets    : list - a list of cleaned target input texts wit SOS (decoder input)\n",
    "        ----------\n",
    "        OUTPUT:\n",
    "        input_sequences  : np.ndarray - a N x max_seq_len numpy array with tokenized \n",
    "                                            and padded input sentences\n",
    "        target_sequences : np.ndarray - a N x max_seq_len numpy array with tokenized \n",
    "                                            and padded target sentences\n",
    "        target_input_sequences : np.ndarray - a N x max_seq_len numpy array with tokenized \n",
    "                                            and padded target input sentences\n",
    "        \"\"\"\n",
    "        \n",
    "        # Fit tokenizers\n",
    "        self._fit_tokenizers(inputs, targets, input_targets)\n",
    "        \n",
    "        # Transform to sequences + padding\n",
    "        input_sequences = self.tokenize_input(inputs)\n",
    "        target_sequences = self.tokenize_output(targets)\n",
    "        target_input_sequences = self.tokenize_output(input_targets)\n",
    "        \n",
    "        return input_sequences, target_sequences, target_input_sequences\n",
    "        \n",
    "    def _fit_tokenizers(self, inputs, targets, input_targets):\n",
    "        \"\"\"Utility function to separate fitting from transforming texts to sequences.\"\"\"\n",
    "        \n",
    "        # Fit tokenizers\n",
    "        self.input_tokenizer.fit_on_texts(inputs)\n",
    "        self.output_tokenizer.fit_on_texts(targets + input_targets)\n",
    "        \n",
    "        # Obtain index 2 word dictionaries\n",
    "        self.idx2word_input = {v : k for k, v in self.input_tokenizer.word_index.items()}\n",
    "        self.idx2word_output = {v : k for k, v in self.output_tokenizer.word_index.items()}\n",
    "        self.word2idx_input = self.input_tokenizer.word_index\n",
    "        self.word2idx_output = self.output_tokenizer.word_index\n",
    "        \n",
    "    def tokenize_input(self, inputs):\n",
    "        return pad_sequences(self.input_tokenizer.texts_to_sequences(inputs), maxlen=self.max_seq_len)\n",
    "    \n",
    "    def tokenize_output(self, outputs):\n",
    "        return pad_sequences(self.output_tokenizer.texts_to_sequences(outputs), maxlen=self.max_seq_len, padding='post')\n",
    "        \n",
    "    def decode_input_sequence(self, sequence):\n",
    "        \"\"\"Decodes a tokenized and padded input sequence.\"\"\"\n",
    "        \n",
    "        return ' '.join([self.idx2word_input[idx] for idx in sequence if idx != 0])\n",
    "    \n",
    "    def decode_output_sequence(self, sequence):\n",
    "        \"\"\"Decodes a tokenized and padded output sequence.\"\"\"\n",
    "        \n",
    "        return ' '.join([self.idx2word_output[idx] for idx in sequence if idx != 0])\n",
    "    \n",
    "    def test_random_dialogs_raw(self, inputs, targets, num_exchanges=5):\n",
    "        \"\"\"A function to test by inspection if the raw dialogs are properly aligned.\"\"\"\n",
    "\n",
    "        indices = np.random.randint(0, len(inputs), num_exchanges)\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            print('Random dialog {}:'.format(idx))\n",
    "            print(inputs[idx])\n",
    "            print(targets[idx])\n",
    "            print('-' * 10)\n",
    "            \n",
    "    def test_random_dialogs_preprocessed(self, inputs, targets, num_exchanges=5):\n",
    "        \"\"\"A function to test by inspection if the preprocessed dialogs are properly aligned.\"\"\"\n",
    "        \n",
    "        indices = np.random.randint(0, inputs.shape[0], num_exchanges)\n",
    "        \n",
    "        for i, idx in enumerate(indices):\n",
    "            print('Random dialog {}:'.format(idx))\n",
    "            print(self.decode_input_sequence(inputs[idx]))\n",
    "            print(self.decode_output_sequence(targets[idx]))\n",
    "            print('-' * 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    \"\"\"The ready made chat bot class utilized after training of the seq2seq model.\"\"\"\n",
    "    def __init__(self, preprocessor, training_model, encoder, decoder, attention, latent_dim=128):\n",
    "        \n",
    "        self.preprocessor = preprocessor\n",
    "        self.training_model = training_model\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.attention = attention\n",
    "        self.latent_dim = latent_dim\n",
    "        self.alphas = []\n",
    "        \n",
    "    def train_model(self, train_gen, val_gen, epochs, save_name, verbose=True):\n",
    "        \"\"\"Intereface to optimize model.\"\"\"\n",
    "        \n",
    "        # Use checkpointing\n",
    "        filepath=\"./checkpoints/weights-{}-best.hdf5\".format(save_name)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=True, save_best_only=True, mode='max')\n",
    "        tb = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "        \n",
    "        # Fit\n",
    "        h = self.training_model.fit_generator(train_gen, \n",
    "                                              validation_data=val_gen, \n",
    "                                              epochs=epochs, \n",
    "                                              verbose=verbose,\n",
    "                                              callbacks=[checkpoint,tb])\n",
    "        \n",
    "    def save_model(self, path, path_encoder, path_decoder):\n",
    "        self.training_model.save_weights(path)\n",
    "        self.encoder.save_weights(path_encoder)\n",
    "        self.decoder.save_weights(path_decoder)\n",
    "    \n",
    "    def load_model(self, path, path_encoder, path_decoder):\n",
    "        self.training_model.load_weights(path)\n",
    "        self.encoder.load_weights(path_encoder)\n",
    "        self.decoder.load_weights(path_decoder)\n",
    "    \n",
    "    def test_model(self, test_sentences, target_sentences, n_sentences=3, static=False):\n",
    "        \"\"\"Judge visually the responses of the model on test sentences (test set or custom).\"\"\"\n",
    "        \n",
    "        # Choose random indices.\n",
    "        indices = np.random.randint(0, test_sentences.shape[0], size=n_sentences)\n",
    "        decoded_targets = []\n",
    "        responses = []\n",
    "        for i, idx in enumerate(indices):\n",
    "            decoded_input_sentence = self.preprocessor.decode_input_sequence(test_sentences[idx, :])\n",
    "            decoded_target_sentence = self.preprocessor.decode_output_sequence(target_sentences[idx, :])\n",
    "            \n",
    "            if self.attention:\n",
    "                response = self.answer_attention(decoded_input_sentence, static)\n",
    "            else:\n",
    "                response = self.answer(decoded_input_sentence)\n",
    "            \n",
    "            #print('Test ', i+1)\n",
    "            #print('Input sentence: ')\n",
    "            #print(decoded_input_sentence)\n",
    "            #print('Chat bot output: ')\n",
    "            #print(response)\n",
    "            #print('Expected target sentence: ')\n",
    "            #print(decoded_target_sentence)\n",
    "            #print('-' * 20)\n",
    "            decoded_targets.append(decoded_target_sentence[:-6].split(\" \")) #discard <eos>\n",
    "            responses.append(response.lower()[:-1].split(\" \")) #discard \".\"\n",
    "        return decoded_targets, responses\n",
    "    \n",
    "    def chat(self, static=False):\n",
    "        \"\"\"Chat interface.\"\"\"\n",
    "        \n",
    "        print(\"Hi, let's talk!\")\n",
    "        print(\"To end the conversation, enter an empty line. :)\")\n",
    "        while True:\n",
    "            txt = input('You: ')\n",
    "            if not txt:\n",
    "                print('Bye!')\n",
    "                break\n",
    "            if self.attention:\n",
    "                response = self.answer_attention(txt, static)\n",
    "            else:\n",
    "                response = self.answer(txt)\n",
    "            print(response)\n",
    "            \n",
    "    def answer_attention(self, question, static=False):\n",
    "        \"\"\"Answer a question with attention.\"\"\"\n",
    "        \n",
    "        text = self.preprocessor.clean_text(question)\n",
    "        encoder_output = self.encoder.predict(self.preprocessor.tokenize_input([text]))\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        # Populate the first character of target sequence with the start character.\n",
    "        target_seq[0, 0] = self.preprocessor.word2idx_output['<sos>']\n",
    "        eos_idx = self.preprocessor.word2idx_output['<eos>']\n",
    "        # Initial states\n",
    "        s, c = np.zeros((1, self.latent_dim)), np.zeros((1, self.latent_dim))\n",
    "        \n",
    "        # Decoder loop\n",
    "        output_sentence = []\n",
    "        for _ in range(self.preprocessor.max_seq_len):\n",
    "            o, s, c = self.decoder.predict([target_seq, encoder_output, s, c])\n",
    "            # Index of next word\n",
    "            #idx = np.argmax(o.flatten())\n",
    "            o_flat = o.flatten()\n",
    "            \n",
    "            if static:\n",
    "                sigma = 0 #don't add noise\n",
    "            else:\n",
    "                sigma = [0, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035]\n",
    "                sigma = np.random.choice(sigma)\n",
    "            \n",
    "            noise = np.random.normal(0,sigma,o_flat.shape[0])\n",
    "            \n",
    "            o_flat = o_flat + noise\n",
    "            \n",
    "            idx = np.argmax(o_flat)\n",
    "            \n",
    "            #apply softmax so probabilities sum to 1\n",
    "            #o_prob = np.exp(o_flat - np.max(o_flat))/(np.sum(np.exp(o_flat - np.max(o_flat))))\n",
    "            \n",
    "            #idx = [x for x in range(o_flat.shape[0])]\n",
    "            #idx = np.random.choice(idx, p=o_prob)\n",
    "            \n",
    "            #idx = np.random.multinomial(1, idx)\n",
    "            #idx = np.argmax(idx)\n",
    "            \n",
    "            #If EOS, end sentence\n",
    "            if idx == eos_idx:\n",
    "                break\n",
    "            if idx > 0:\n",
    "                word = self.preprocessor.idx2word_output[idx]\n",
    "                output_sentence.append(word)\n",
    "            # Update the decoder input which is just the word previously generated\n",
    "            target_seq[0, 0] = idx\n",
    "        # Try to guess if question or no (we coult have learnt that, just use for prettines)\n",
    "        if len(output_sentence) == 0:\n",
    "            end_char = '.'\n",
    "        else:\n",
    "            if output_sentence[0] in ['what', 'where', 'how', 'who', 'why', 'when', 'which', 'are']:\n",
    "                end_char = '?'\n",
    "            else:\n",
    "                end_char = '.'\n",
    "        # Return pretty sentence\n",
    "        return ' '.join(output_sentence).capitalize() + end_char\n",
    "        \n",
    "    def answer(self, question):\n",
    "        \"\"\"Answer a question.\"\"\"\n",
    "        \n",
    "        # Clean (just in case)\n",
    "        text = self.preprocessor.clean_text(question)\n",
    "        \n",
    "        # Encode the input as state vectors.\n",
    "        states = self.encoder.predict(self.preprocessor.tokenize_input([text]))\n",
    "        \n",
    "        # Generate empty target sequence of length 1 (language generation model)\n",
    "        target_seq = np.zeros((1, 1))\n",
    "\n",
    "        # Populate the first character of target sequence with the start character.\n",
    "        target_seq[0, 0] = self.preprocessor.word2idx_output['<sos>']\n",
    "        eos_idx = self.preprocessor.word2idx_output['<eos>']\n",
    "        \n",
    "        # Output sequence\n",
    "        output_sentence = []\n",
    "        for _ in range(self.preprocessor.max_seq_len):\n",
    "            output_tokens, h, c = self.decoder.predict([target_seq] + states)\n",
    "            # Get next word (most probable)\n",
    "            idx = np.argmax(output_tokens[0, 0, :])\n",
    "            #idx = np.random.multinomial(20, output_tokens[0, 0, :])\n",
    "            #idx = np.argmax(idx)\n",
    "            #If EOS, end sentence\n",
    "            if idx == eos_idx:\n",
    "                break\n",
    "            if idx > 0:\n",
    "                word = self.preprocessor.idx2word_output[idx]\n",
    "                output_sentence.append(word)\n",
    "            # Update the decoder input which is just the word previously generated\n",
    "            target_seq[0, 0] = idx\n",
    "            # Update states\n",
    "            states = [h, c]\n",
    "        # Try to guess if question or no (we coult have learnt that, just use for prettines)\n",
    "        if output_sentence[0] in ['what', 'where', 'how', 'who', 'why', 'when', 'which', 'are']:\n",
    "            end_char = '?'\n",
    "        else:\n",
    "            end_char = '.'\n",
    "        # Return pretty sentence\n",
    "        return ' '.join(output_sentence).capitalize() + end_char\n",
    "    \n",
    "    def _temperature(self, output_tokens):\n",
    "        \"\"\"Reweight softmax distribution.\"\"\"\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq2seq(preprocessor, lstm_dim=128, embedding_dim=100, \n",
    "                  dropout_rate=0.5, encoder_embeddings=None, decoder_embeddings=None):\n",
    "    \"\"\"Creates the seq2seq model for training and prediction.\"\"\"\n",
    "    \n",
    "    ### TRAINING\n",
    "\n",
    "    # Encoder input\n",
    "    encoder_input = Input(shape=(preprocessor.max_seq_len, ))\n",
    "\n",
    "    # Encoder embedding\n",
    "    encoder_embedding = Embedding(\n",
    "                    input_dim=preprocessor.vocab_size, \n",
    "                    output_dim=embedding_dim,\n",
    "                    weights=[encoder_embeddings],\n",
    "                    input_length=preprocessor.max_seq_len,\n",
    "                    trainable=False\n",
    "    )\n",
    "    encoder_X = encoder_embedding(encoder_input)\n",
    "\n",
    "    # Encoder LSTM\n",
    "    encoder_drop = GaussianDropout(dropout_rate)(encoder_X)\n",
    "    encoder_lstm = LSTM(lstm_dim, return_state=True)\n",
    "    encoder_outputs, h, c = encoder_lstm(encoder_drop)\n",
    "\n",
    "    # \"Thought vector\"\n",
    "    encoder_states = [h, c]\n",
    "\n",
    "    # Decoder input\n",
    "    decoder_input = Input(shape=(preprocessor.max_seq_len, ))\n",
    "\n",
    "    # Decoder embedding\n",
    "    decoder_embedding = Embedding(\n",
    "                input_dim=preprocessor.vocab_size, \n",
    "                output_dim=embedding_dim,\n",
    "                weights=[decoder_embeddings],\n",
    "                input_length=preprocessor.max_seq_len,\n",
    "                trainable=False\n",
    "    )      \n",
    "    decoder_X = decoder_embedding(decoder_input)\n",
    "\n",
    "    # Decoder LSTM\n",
    "    decoder_drop = GaussianDropout(dropout_rate)(decoder_X)\n",
    "    decoder_lstm = LSTM(lstm_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_drop, initial_state=encoder_states)\n",
    "\n",
    "    # Softmax classifier\n",
    "    decoder_dense = Dense(preprocessor.vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Model definition and compilation\n",
    "    training_model = Model([encoder_input, decoder_input], decoder_outputs)\n",
    "    \n",
    "    ### PREDICTION MODEL\n",
    "    \n",
    "    # The encoder will output the initial decoder hidden state\n",
    "    encoder_model = Model(encoder_input, encoder_states)\n",
    "\n",
    "    decoder_state_input_h = Input(shape=(lstm_dim,))\n",
    "    decoder_state_input_c = Input(shape=(lstm_dim,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_input_single = Input(shape=(1,))\n",
    "    decoder_input_single_x = decoder_embedding(decoder_input_single)\n",
    "\n",
    "    # this time, we want to keep the states too, to be output\n",
    "    # by our sampling model\n",
    "    decoder_outputs, h, c = decoder_lstm(\n",
    "      decoder_input_single_x,\n",
    "      initial_state=decoder_states_inputs\n",
    "    )\n",
    "\n",
    "    decoder_states = [h, c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # The sampling model\n",
    "    decoder_model = Model(\n",
    "      [decoder_input_single] + decoder_states_inputs, \n",
    "      [decoder_outputs] + decoder_states\n",
    "    )\n",
    "\n",
    "    # Compile the training model\n",
    "    training_model.compile(\n",
    "      optimizer='rmsprop',\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return training_model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_seq2seq(preprocessor, lstm_dim=128, embedding_dim=100, \n",
    "                  dropout_rate=0.5, encoder_embeddings=None, decoder_embeddings=None):\n",
    "    \"\"\"Creates the seq2seq model with attention for training and prediction.\"\"\"\n",
    "    \n",
    "    \n",
    "    ### TRAINING ###\n",
    "    # -------------------------------- #\n",
    "    \n",
    "    ## ENCODER ##\n",
    "    # Encoder input\n",
    "    encoder_input = Input(shape=(preprocessor.max_seq_len, ))\n",
    "\n",
    "    # Encoder embedding\n",
    "    encoder_embedding = Embedding(\n",
    "                    input_dim=preprocessor.vocab_size, \n",
    "                    output_dim=embedding_dim,\n",
    "                    weights=[encoder_embeddings],\n",
    "                    input_length=preprocessor.max_seq_len,\n",
    "                    trainable=False\n",
    "    )\n",
    "    encoder_X = encoder_embedding(encoder_input)\n",
    "    \n",
    "    # Encoder is a bidirection lstm\n",
    "    encoder_drop = GaussianDropout(dropout_rate)(encoder_X)\n",
    "    encoder_lstm = Bidirectional(LSTM(lstm_dim, return_sequences=True))\n",
    "    encoder_outputs  = encoder_lstm(encoder_drop)\n",
    "    \n",
    "    ## DECODER ##\n",
    "    # Decoder input\n",
    "    decoder_input = Input(shape=(preprocessor.max_seq_len, ))\n",
    "\n",
    "    # Decoder embedding\n",
    "    decoder_embedding = Embedding(\n",
    "                input_dim=preprocessor.vocab_size, \n",
    "                output_dim=embedding_dim,\n",
    "                weights=[decoder_embeddings],\n",
    "                input_length=preprocessor.max_seq_len,\n",
    "                trainable=False\n",
    "    )      \n",
    "    decoder_X = decoder_embedding(decoder_input)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attn_repeat_layer = RepeatVector(preprocessor.max_seq_len)\n",
    "    attn_concat_layer = Concatenate(axis=-1)\n",
    "    attn_dense1 = Dense(12, activation='tanh')\n",
    "    attn_dense2 = Dense(1)\n",
    "    attn_softmax = Softmax(axis=1)\n",
    "    attn_dot = Dot(axes=1)\n",
    "    \n",
    "    # Decoder LSTM\n",
    "    decoder_lstm = LSTM(lstm_dim, return_state=True)\n",
    "    decoder_dense = Dense(preprocessor.vocab_size, activation='softmax')\n",
    "    initial_s = Input(shape=(lstm_dim, ), name='s0') # hidden state\n",
    "    initial_c = Input(shape=(lstm_dim, ), name='c0') # cell state\n",
    "    context_last_word_concat = Concatenate(axis=2) # use for teacher forcing\n",
    "    \n",
    "    # Now we obtain the output in Ty steps\n",
    "    # In each step, we consider all encoder outputs and current s, and c\n",
    "    s = initial_s\n",
    "    c = initial_c\n",
    "    \n",
    "    outputs = []\n",
    "    # Loop for each output step\n",
    "    for t in range(preprocessor.max_seq_len):\n",
    "        \n",
    "        # Get context for step t\n",
    "        st_1 = attn_repeat_layer(s)\n",
    "        x_att = attn_concat_layer([encoder_outputs, st_1])\n",
    "        alphas = attn_dense1(x_att)\n",
    "        alphas = attn_dense2(alphas)\n",
    "        alphas = attn_softmax(alphas)\n",
    "        context = attn_dot([alphas, encoder_outputs])\n",
    "        \n",
    "        # Select previous word for teacher forcing\n",
    "        selector = Lambda(lambda x: x[:, t:t+1])\n",
    "        target_x_t = selector(decoder_X)\n",
    "        \n",
    "        # Combine context with previous word and get decoder output at step t\n",
    "        decoder_X_t = context_last_word_concat([context, target_x_t])\n",
    "        o, s, c = decoder_lstm(decoder_X_t, initial_state=[s, c])\n",
    "        \n",
    "        # Get next word prediction and add to outputs list\n",
    "        decoder_output = decoder_dense(o)\n",
    "        outputs.append(decoder_output)\n",
    "        \n",
    "    # Combine all the outputs from the list \n",
    "    # The list now contains Ty NxD matrices\n",
    "    # where N is the batch_size and D is the vocab_size\n",
    "    # Thus, we want a NxTyxD tensor => permute the stacked tensor which is TyxNxD\n",
    "    output_combiner = Lambda(lambda x: K.permute_dimensions(K.stack(x), pattern=(1, 0, 2)), name='Combiner')\n",
    "    outputs_stacked = output_combiner(outputs)\n",
    "    \n",
    "    # Create and compile the training model\n",
    "    training_model = Model(\n",
    "            inputs=[encoder_input, decoder_input, initial_s, initial_c],\n",
    "            outputs=outputs_stacked\n",
    "    )\n",
    "    \n",
    "    training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    ### PREDICTION ###\n",
    "\n",
    "    # Encoder\n",
    "    encoder_model = Model(encoder_input, encoder_outputs)\n",
    "    \n",
    "    # Decoder (with Ty = 1)\n",
    "    encoder_output_as_input = Input(shape=(preprocessor.max_seq_len, lstm_dim * 2, ))\n",
    "    decoder_input_single = Input(shape=(1,))\n",
    "    decoder_input_single_x = decoder_embedding(decoder_input_single)\n",
    "    \n",
    "    # Attention\n",
    "    st_1 = attn_repeat_layer(initial_s)\n",
    "    x_att = attn_concat_layer([encoder_output_as_input, st_1])\n",
    "    alphas = attn_dense1(x_att)\n",
    "    alphas = attn_dense2(alphas)\n",
    "    alphas = attn_softmax(alphas)\n",
    "    context = attn_dot([alphas, encoder_output_as_input])\n",
    "    \n",
    "    # Decoder lstm\n",
    "    decoder_lstm_input = context_last_word_concat([context, decoder_input_single_x])\n",
    "    o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "    decoder_outputs = decoder_dense(o)\n",
    "    \n",
    "    decoder_model = Model(\n",
    "        inputs=[decoder_input_single, encoder_output_as_input, initial_s, initial_c], \n",
    "        outputs=[decoder_outputs, s, c]\n",
    "    )\n",
    "    \n",
    "    return training_model, encoder_model, decoder_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = get_cornell('dialogs/cornell_movie-dialogs_corpus/', encoding='utf-8')\n",
    "preprocessor = Seq2SeqPreprocessor(vocab_size=20000)\n",
    "inputs_cleaned, targets_cleaned, targets_input_cleaned = preprocessor.clean_texts(questions, answers)\n",
    "input_sequences, target_sequences, target_input_sequences = preprocessor.tokenize_texts(inputs_cleaned, \n",
    "                                                                                        targets_cleaned, \n",
    "                                                                                        targets_input_cleaned)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(input_sequences_train, \n",
    "input_sequences_test, \n",
    "target_sequences_train, \n",
    "target_sequences_test, \n",
    "target_input_sequences_train, \n",
    "target_input_sequences_test) = train_test_split(input_sequences, \n",
    "                                                target_sequences, \n",
    "                                                target_input_sequences, \n",
    "                                                test_size=0.025, \n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_embeddings = load_embeddings('embeddings', \n",
    "                                     preprocessor.word2idx_input, \n",
    "                                     preprocessor.vocab_size)\n",
    "\n",
    "\n",
    "decoder_embeddings = load_embeddings('embeddings', \n",
    "                                     preprocessor.word2idx_output, \n",
    "                                     preprocessor.vocab_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Train generator\n",
    "seq_gen_train = SequenceGenerator(input_sequences_train, \n",
    "                            target_input_sequences_train, \n",
    "                            target_sequences_train, \n",
    "                            batch_size=64, \n",
    "                            n_classes=preprocessor.vocab_size,\n",
    "                            attention=ATTENTION,\n",
    "                            latent_dim=128)\n",
    "\n",
    "# Validation generator\n",
    "seq_gen_val = SequenceGenerator(input_sequences_test, \n",
    "                            target_input_sequences_test, \n",
    "                            target_sequences_test, \n",
    "                            batch_size=64, \n",
    "                            n_classes=preprocessor.vocab_size,\n",
    "                            attention=ATTENTION,\n",
    "                            latent_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_gen_train = SequenceGenerator(input_sequences, \n",
    "                            target_input_sequences, \n",
    "                            target_sequences, \n",
    "                            batch_size=64, \n",
    "                            n_classes=preprocessor.vocab_size,\n",
    "                            attention=ATTENTION,\n",
    "                            latent_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "\n",
    "if ATTENTION:\n",
    "    # Attention seq2seq\n",
    "    model, encoder_model, decoder_model = create_attention_seq2seq(preprocessor, \n",
    "                                                    encoder_embeddings=encoder_embeddings, \n",
    "                                                    decoder_embeddings=decoder_embeddings)\n",
    "else:\n",
    "    # Vanilla seq2seq\n",
    "    model, encoder_model, decoder_model = create_seq2seq(preprocessor, \n",
    "                                                        encoder_embeddings=encoder_embeddings, \n",
    "                                                        decoder_embeddings=decoder_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = ChatBot(preprocessor, model, encoder_model, decoder_model, attention=ATTENTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"./weights/seq2seq_attention_\"\n",
    "chatbot.load_model(prefix + \"weights_epoch_50.h5\", prefix + \"encoder_weights_epoch_50.h5\", prefix + \"decoder_weights_epoch_50.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "s0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 50, 256)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 50, 128)      0           s0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 50, 384)      0           input_3[0][0]                    \n",
      "                                                                 repeat_vector[50][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50, 12)       4620        concatenate[50][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50, 1)        13          dense[50][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 50, 1)        0           dense_1[50][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 256)       0           softmax[50][0]                   \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         multiple             2000000     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 356)       0           dot[50][0]                       \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)        [(None, 128), (None, 248832      concatenate_1[50][0]             \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20000)        2580000     cu_dnnlstm_1[50][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,833,465\n",
      "Trainable params: 2,833,465\n",
      "Non-trainable params: 2,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild a model identical to decoder_model, but only up to the softmax layer we want to extract results from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder input\n",
    "decoder_input = Input(shape=(preprocessor.max_seq_len, ))\n",
    "\n",
    "# Decoder embedding\n",
    "decoder_embedding = Embedding(\n",
    "            input_dim=preprocessor.vocab_size, \n",
    "            output_dim=100,\n",
    "            weights=[decoder_embeddings],\n",
    "            input_length=preprocessor.max_seq_len,\n",
    "            trainable=False\n",
    ")      \n",
    "decoder_X = decoder_embedding(decoder_input)\n",
    "\n",
    "\n",
    "# Attention mechanism\n",
    "attn_repeat_layer = RepeatVector(preprocessor.max_seq_len)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(12, activation='tanh')\n",
    "attn_dense2 = Dense(1)\n",
    "attn_softmax = Softmax(axis=1)\n",
    "\n",
    "####\n",
    "\n",
    "initial_s = Input(shape=(128, ), name='s0') # hidden state\n",
    "initial_c = Input(shape=(128, ), name='c0') # cell state\n",
    "\n",
    "encoder_output_as_input = Input(shape=(preprocessor.max_seq_len, 128 * 2, ))\n",
    "decoder_input_single = Input(shape=(1,))\n",
    "decoder_input_single_x = decoder_embedding(decoder_input_single)\n",
    "\n",
    "# Attention\n",
    "st_1 = attn_repeat_layer(initial_s)\n",
    "x_att = attn_concat_layer([encoder_output_as_input, st_1])\n",
    "alphas = attn_dense1(x_att)\n",
    "alphas = attn_dense2(alphas)\n",
    "alphas = attn_softmax(alphas)\n",
    "\n",
    "intermediate_layer_model = Model(inputs=[decoder_input_single, encoder_output_as_input, initial_s, initial_c],\n",
    "                                 outputs=alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "s0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 50, 256)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_9 (RepeatVector)  (None, 50, 128)      0           s0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 50, 384)      0           input_24[0][0]                   \n",
      "                                                                 repeat_vector_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 50, 12)       4620        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 50, 1)        13          dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "softmax_9 (Softmax)             (None, 50, 1)        0           dense_20[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,633\n",
      "Trainable params: 4,633\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "intermediate_layer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the weights from the decoder to our intermediate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for layer in intermediate_layer_model.layers:\n",
    "    w = decoder_model.layers[count].get_weights()\n",
    "    layer.set_weights(w)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk to the model and save the softmax results/alphas/attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(preprocessor, intermediate_layer_model, encoder_model, question, static=False):\n",
    "    text = preprocessor.clean_text(question)\n",
    "    encoder_output = encoder_model.predict(preprocessor.tokenize_input([text]))\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = preprocessor.word2idx_output['<sos>']\n",
    "    eos_idx = preprocessor.word2idx_output['<eos>']\n",
    "    # Initial states\n",
    "    s, c = np.zeros((1, 128)), np.zeros((1, 128))\n",
    "\n",
    "    output_sentence = []\n",
    "    alphas = np.zeros((preprocessor.max_seq_len,preprocessor.max_seq_len,1))\n",
    "    length_of_response = 0\n",
    "    for i in range(preprocessor.max_seq_len):\n",
    "        o, s, c = decoder_model.predict([target_seq, encoder_output, s, c])\n",
    "        intermediate_output = intermediate_layer_model.predict([target_seq, encoder_output, s, c])\n",
    "        alphas[i] = intermediate_output\n",
    "    \n",
    "        o_flat = o.flatten()\n",
    "            \n",
    "        if static:\n",
    "            sigma = 0 #don't add noise\n",
    "        else:\n",
    "            sigma = [0, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035]\n",
    "            sigma = np.random.choice(sigma)\n",
    "\n",
    "        noise = np.random.normal(0,sigma,o_flat.shape[0])\n",
    "\n",
    "        o_flat = o_flat + noise\n",
    "\n",
    "        idx = np.argmax(o_flat)\n",
    "\n",
    "        #If EOS, end sentence\n",
    "        if idx == eos_idx:\n",
    "            length_of_response = i\n",
    "            break\n",
    "        if idx > 0:\n",
    "            word = preprocessor.idx2word_output[idx]\n",
    "            output_sentence.append(word)\n",
    "        # Update the decoder input which is just the word previously generated\n",
    "        target_seq[0, 0] = idx\n",
    "        \n",
    "    #plot\n",
    "    a = alphas.reshape((50,50))\n",
    "    y_labels = text.split(\" \")\n",
    "    \n",
    "    fig, ax1 = plt.subplots(1,1)\n",
    "    img = ax1.imshow(a[:(len(y_labels)),:(len(output_sentence))])\n",
    "    ax1.set_xticks(np.arange(len(output_sentence)))\n",
    "    ax1.set_yticks(np.arange(len(y_labels)))\n",
    "    ax1.set_xticklabels(output_sentence)\n",
    "    ax1.set_yticklabels(y_labels)\n",
    "    fig.colorbar(img)\n",
    "    \n",
    "    #return plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention(preprocessor, intermediate_layer_model, encoder_model, \"Where are you going?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
